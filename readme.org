#+title: DERP Simulation
#+author: Alexander E. Zarebski

This repository contains the code to simulate a database of
phylogenetic trees that will be used in a machine learning project in
which a neural network will be trained to solve phylodynamics
problems.

* Usage

** Getting started generating a database

To generate the database, run the main script:

#+begin_src sh
 python main.py <path/to/config.json>
#+end_src

If you want a small example to test this out, try using the
=config/debugging.json= file. The whole simulation is configured by
the JSON file provided at the command line.

*** Optional monitoring progress

Making a large database takes a while. There is a tool in
=src/monitor.py= which you can run and it will report on the progress
of a current database construction and give a (rough) estimate of the
remaining time for each stage of the simulation.

#+begin_src sh
 python src/monitor.py <path/to/config.json>
#+end_src

** Configuring a simulation

The way in which a dataset is simulated is configured with a JSON
file. There is a schema for valid configurations described [[file:./config/readme.org][here]]. There
are some example configurations provided:

- [[file:./config/debugging.json][debugging]]
- [[file:./config/simulation-charmander.json][Charmander]]
- [[file:./config/simulation-charmander-contemporaneous.json][Charmander with a contemporaneous sample]]
- [[file:./config/simulation-charmeleon.json][Charmeleon]]
- [[file:./config/simulation-charizard.json][Charizard]]

Additional information about these datasets is given [[file:./config/readme.org][here]].

** Visualising the data

Two scripts, =visualisation.py= and =visualisation_temporal.py= can be
used to visualise the output of a simulation.

#+begin_src sh
 python visualisation.py <path/to/config.json>
 python visualisation_temporal.py <path/to/config.json>
#+end_src

Note that the latter only applies for simulations which are configured
to report temporal data (that is, =report_temporal_data= is set to
=true= in the config).

** Database structure

The database is an HDF5 file. Each simulation is represented with a
group with a name of the form =record_xxxxxx=, e.g. =record_000123=.
The data from each simulation is split into two groups: =input= and
=output=.

*** Input

The =input= group has the following datasets:

- =present= :: the time since the origin of the last sequenced sample
- =tree_height= :: the time between the $T_{\text{MRCA}}$ and the
  present
- =tree= :: a binary blob which is the pickled reconstructed tree of
  the sequenced samples in the simulation.

*** Output

The =output= group contains a lot of measurements, but the most
important is the =temporal_measurements= dataset. The
=temporal_measurements= dataset has the following columns:

- =measurement_times= (float) :: the (forward) time since the origin
  of the measurements
- =prevalence= (int) :: the number of infected individuals
- =cumulative= (int) :: the cumulative number of infections
- =reproductive_number= (float) :: the reproduction number

** TODO Using the database

The following demonstrates how to use the database in Python. Don't
forget to close the database connection after using it!

#+begin_src python
db_conn = h5py.File("dataset.hdf5")
for k in db_conn.keys():
    out_grp = db_conn[k]['output']
    r0_vals = out_grp['parameters']['r0']['values'][()]
    r0_chng = out_grp['parameters']['r0']['change_times'][()]
    prev = out_grp["present_prevalence"][()]
    print(f"Record {k} prevalence {prev}")
    tree = pickle.loads(db_conn[k]['input']['tree'][...].tobytes())
db_conn.close()
#+end_src

If you want a GUI to inspect the output HDF5 file, the [[https://github.com/HDFGroup/hdf-compass][HDFCompass]] tool
provides a simple way to inspect the data that has been generated.
There is some basic information about the simulation stored as
attributes in the HDF5 file. This includes the date of creation and
the size of the dataset.

** Conda environment

A conda environment to run this simulation can be created from the
=environment.yaml= file by running the following command:

#+begin_src sh
  conda env create -f environment.yaml
#+end_src

This environment will have all the correct packages for running the
simulations.

** Installing BEAST2

BEAST2 is used to simulate the data. If you don't have BEAST2
installed, there is a script =scr/setuplib.sh= which will download and
install this for you. Once you have BEAST2 installed, you will need to
install [[https://tgvaughan.github.io/remaster/][remaster]] through BEAUti.
