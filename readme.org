#+title: DERP: Deep recursive parameter estimation
#+author: Alexander E. Zarebski

This repository contains the code to simulate a database of
phylogenetic trees that will be used in a machine learning project in
which a neural network will be trained to solve phylodynamics
problems.

* Roadmap

- [-] Provide a single database file and some helper functions to read
  trees out and their associated metadata.
  + [-] There should be a bunch of visualisation so that we can get a
    feel for if the parameters of the simulation are at all plausible.
    * [X] Visualisation of change points
    * [X] Histogram of the last sequenced sample time
    * [ ] Histogram of prevalence
    * [ ] Histogram of cumulative infections
  + [X] There should be a file to specify the conda environment used
    and instructions on how to recreate this.
  + [X] Establish the prior distribution to draw simulation parameters
    from, these will need to be sufficiently large to cover the range
    of plausible values for the use cases.
  + [X] This should be robust to failed simulations and include basic
    metadata of the simulation such as the dataset size and the date
    it was created.
  + [X] Store the trees and metadata in a single database file.
    * [X] Split the creation of the intermediate pickle files across
      multiple workers in the same way we split the BEAST2
      simulations.
    * [X] Write a function that loads all the data from one simulation
      into the database.
  + [ ] Rename =main.py= to =simulate.py= or something similar for
    clarity.
  + [ ] Include a JSON schema for the configuration files and then
    check that the one supplied at the command line is valid.
  + [ ] For each dataset, there should be an analogous version in
    which the sampling is all done at the present. This will be a bit
    of work but will make the simulations meaningfully more
    expressive.
    * [ ] Create a new remaster template which does a contemporary
      sample.
    * [ ] Include contemporary sampling configuration in =main.py=.
    * [ ] Create a new configuration
      =simulation-<name>-contemporary.json= for the new instances.
    * [ ] Extend the plotting to work in the case of contemporary
      sampling.
  + [ ] Document how to use the database file.
    * [ ] There should be a helper function which explains how to read
      trees and their corresponding record out.

* Usage

** Building the database

To generate the database, run the main script.

#+begin_src sh
 python main.py <path/to/config.json>
#+end_src

** Using the database

The following demonstrates how to use the database. Don't forget to
close the database connection after using it!

#+begin_src python
db_conn = h5py.File("dataset.hdf5")
for k in db_conn.keys():
    out_grp = db_conn[k]['output']
    r0_vals = out_grp['parameters']['r0']['values'][()]
    r0_chng = out_grp['parameters']['r0']['change_times'][()]
    prev = out_grp["present_prevalence"][()]
    print(f"Record {k} prevalence {prev}")
    tree = pickle.loads(db_conn[k]['input']['tree'][...].tobytes())
db_conn.close()
#+end_src

** Conda environment

A conda environment to run this simulation can be created from the
=environment.yaml= file by running the following command:

#+begin_src sh
  conda env create -f environment.yaml
#+end_src

* Datasets

There are a sequence of configurations: /Charmander/, /Charmeleon/ and
/Charizard/. These all use the same model but are of increasing size
and use broader distributions over the simulation parameters.

** Charmander

This is intended as a toy dataset. It has a 800-100-100
training-validation-testing split. The parameters are nearly constant
through time, for example, the $R_0$ values are shown in Figure
[[fig:charmander-r0s]]. The configuration for this simulation is
[[file:./config/simulation-charmander.json][simulation-charmander.json]].

#+caption: The reproduction number through time in a subsample of the Charmander simulations.
#+name: fig:charmander-r0s
#+attr_org: :width 500px
#+attr_html: :width 400px
[[./out/sim-charmander/plots/r0_trajectories.png]]

** Charmeleon

This is intended as a small dataset. It has a 1600-200-200
training-validation-testing split. The parameters vary significantly
through time, for example, the $R_0$ values are shown in Figure
[[fig:charmeleon-r0s]]. The configuration for this simulation is
[[file:./config/simulation-charmeleon.json][simulation-charmeleon.json]].

#+caption: The reproduction number through time in a subsample of the Charmeleon simulations.
#+name: fig:charmeleon-r0s
#+attr_org: :width 500px
#+attr_html: :width 400px
[[./out/sim-charmeleon/plots/r0_trajectories.png]]

* Notes

1. Activate the =derp= environment in conda and run =python main.py
   config/debugging.json= to run the debugging example. This will
   produce a bunch of pickle files, each containing a single record of
   the dataset and a HDF5 file which contains the pickled trees as
   binary blobs and the various parameters and statistics that we
   might be interested in estimating from those trees. The relevant
   files are all defined at the start of =main.py= as global variables
   read from the configuration JSON file.
2. To set up BEAST2 to do the simulation you can run the
   =src/setuplib.sh= script which will download BEAST2. Run =python
   clean.py= to remove output to start again fresh. Run =bash
   src/housekeeping.sh= to update =environment.yaml= and lint the
   code.
3. If you want a GUI to inspect the output HDF5 file, the [[https://github.com/HDFGroup/hdf-compass][HDFCompass]]
   tool provides a simple way to inspect the data that has been
   generated. There is some basic information about the simulation
   stored as attributes in the HDF5 file. This includes the date of
   creation and the size of the dataset.
